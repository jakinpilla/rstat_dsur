---
title: "ch07_2"
author: "Daniel_Kim"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: 
    html_notebook: 
      toc_float: true
      toc : true
      toc_depth : 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message = FALSE, warning = FALSE}
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
# install.packages('epiDisplay')
library(epiDisplay)
library(knitr)
```

### 7.1. 이번 장에서 배우는 내용

<br>

### 7.2 회귀의 소개
 
 - 단순회귀, 다중회귀

 - 최소제곱법(method of least squares) 수학적 기법을 이용해 자료를 가장 잘 서술하는 직선을 선택
 
<br>

#### 7.2.1 직선에 관한 중요한 정보 몇 가지
 
 - 기울기 $b_{1}$, 절편 $b_{0}$

 - $b_{1}$, $b_{0}$들을 회귀계수라고 한다. 

$$Y_{i} = (b_{0} + b_{1} X_{i}) + \epsilon_{i}$$

<br>

#### 7.2.2. 최소제곱법

 - line of best fit

<br>

#### 7.2.3. 적합도 평가: 제곱합, r, $R^{2}$

 - 평균 값과 관측값의 차이를 구하고, 그 차이 제곱들의 합을 총제곱합(total sum of squares)라고 한다. 총제곱합을 $SS_{T}$로 표기한다.  $SS_{T}$는 관측자료와 Y의 평균값의 차이들로 계산한 값이다.
 
 - $\sum(O_{i} - M_{i})^{2}$ 을 제곱잔차합 또는 잔차제곱합이라고 하고 $SS_{R}$로 표기한다. $SS_{R}$은 관측자료와 회귀선의 차이들로 계산한 값이다. 
 
 - $SS_{T}$와 $SS_{R}$의 차이는 평균 대신 회귀모형을 사용했을 때 예측이 얼마나 향상되었는지를 나타낸다. 다른 말로 하면 그 차이는 회귀모형을 사용했을 때 부정확도가 얼마나 줄어들 것이지를 보여준다. 이러한 향상량을 모형제곱합(model sum of squares)이라 부르고 $SS_{M}$으로 표기한다. $SS_{M}$은 Y의 평균값과 회귀선의 차이들로 이루어진다. 
 
 - $SS_{M}$의 값이 크다느 것은 결과변수의 예측을 위해 평균을 사용하는 것과 회귀모형을 사용하는 것이 많이 다르다는 뜻이다. 평균은 가장 기본적인 모형이므로, 이 값이 크다는 것은 회귀모형이 이전보다 결과변수를 훨씬 잘 예측함을 의미한다. 
 
 - $R^{2}$은 가장 기본적인 모형이 설명하는 변동의 양($SS_{T}$)에 대한, 주어진 모형이 설명하는 변동의 양($SS_{M}$)의 비를 나타낸다. 
 
 $$R^{2} = \frac{SS_{M}}{SS_{T}}$$
 
 - $R^{2}$의 제곱근은 곧 피어슨 상관계수이다. 그런 만큼, 단순회귀에서 상관계수 $r$은 회귀모형의 전반적인 적합도를 잘 추정하는 값이며 $R^{2}$은 상관관계의 실질적인 크기를 잘 추정하는 값이다. 
 
 - $F$ 같은 검정통계량들은 체계적 변동의 양을 비체계적 변동의 양으로 나눈 것이다. 다른 말로 하면 모형과 모형의 오차를 비교한 것이다. 회귀분석에서 $F$는 $SS_{M}(모형에 의한 향상)$과 $SS_{R}(모형과 관측값의 차이)$의 비이다. 
 
 - 그런데 제곱합은 합한 차이들의 수에 의존하므로, 실제로는 평균 제곱들의 합을 사용한다. 그러한 합을 평균제곱(mean squares, MS)라고 한다. 이것은 그냥 제곱합을 자유도로 나누면 된다. 
 
 - $SS_{M}$의 자유도는 모형의 변수 개수이고 $SS_{R}$의 자유도는 회귀분석으로 추정하는 매개변수(모수) 개수를 관측값 개수에서 뺀 것이다. (이는 곧 상수를 포함한 베타 계수들의 개수이다.) 이 자유도들로 해당 제곱합을 나누면 모형의 평균제곱($MS_{M}$)과 잔차 평균제곱($MS_{R}$)이 나온다. 
 
 - $F$비는 기본모형을 사용했을 때와 비교할 때 새 모형이 결과의 예측을 얼마나 향상시키는지를 나타낸다. 
 
 $$F =  \frac{MS_{M}}{MS_{R}}$$
 
<br>
 
#### 7.2.4. 개별 예측변수의 평가
 
 - 만일 어떤 변수가 결과를 유의하게 예측한다면, 해당 $b$값이 0과는 달라야 한다. 이 가설을 $t$ 검증으로 검사할 수 있다. t-검정량은 $b$의 값이 0이라는 귀무가설을 검증한다. 따라서, 만일 그 검사의 결과가 유의하다면 해당 예측변수가 결과를 예측하는 능력에 유의하게 기여한다는 확신이 커진다.
 
-  우리의 관심사는 $b$가 그 추정값의 오차보다 큰 가이다. t검정은 표본 b 값들의 변동을 기준으로 할 때 모형의 b 값이 0과 조금만 달라도 의미 있는 차이로 해석할 수 있다. 

- 귀무가설이 $b$가 0이라는 것이므로, 결과적으로 t 통계량은 그냥 $b$의 관측값을 해당 표준오차로 나눈 것이다.

$$t = \frac{b_{관측} - b_{기대}}{SE_{b}}$$

$$t = \frac{b_{관측}}{SE_{b}}$$

- R은 $b$가 실제로 0일때 그러한 t의 관측값(또는 그보다 더 큰 값)이 발생할 정확한 확률을 제공한다. 이 유의확률이 .05보다 작으면 과학자들은 b가 0과 유의하게 다르다고 가정하는 것이다.

```{r}
album1 <- read.delim('Album Sales 1.dat', header = T)
```

```{r}
albumSales.1 <- lm(sales ~ adverts, data =album1)
albumSales.1 %>% summary()
```

<br>

#### 7.5.1 모형의 전반적인 적합도

- Multiple R-squared:  0.3346,	Adjusted R-squared:  0.3313 

```{r}
sqrt(0.3346)
```

- 두 변수(sales, adverts)간의 상관계수는 .58이다. 

- $R^{2}$이 .335라는 것은 광고비가 판매량 변동의 33.5%를 설명한다는 의미이다.

- F-statistic: 99.59 on 1 and 198 DF,  p-value: < 2.2e-16

- $F$비와 $p-value$가 있는데, 이 결과는 $p < .001$ 수준에서 유의하다. 즉, 이 회귀모형을 이용해서 음반 판매량을 예측하는 것이 음반 판매량의 평균을 사용해서 판매량을 예측할 때보다 유의하게 더 낫다는 결론을 내릴 수 있다. 

<br>

#### 7.5.2. 모형 매개변수들

- (Intercept) 1.341e+02  7.537e+00  17.799   <2e-16 에서 t 값을 계산하면

```{r}
134.10 / 7.537
```

- adverts     9.612e-02  9.632e-03   9.979   <2e-16 에서 t 값을 계산하면

```{r}
0.096/0.0096
```

<br>

#### 7.5.3. 모형의 활용

<br>

#### 핵심정리

- $R^{2}$은 애초에 존재하는 변동 중 모형이 설명하는 변동이 얼마나 되는지를 말해준다. 이 값은 결과변수의 변동 중 예측변수의 변동과 공유되는 부분의 비율이다.

- $F$비는 모형으로 설명할 수 없는 변동에 대한 모형으로 설명할 수 있는 변동의 비이다. 이것은 모형이 얼마나 나쁜지를 기준으로 모형이 얼마나 좋은지를 나타낸 것이다. 

$$album sales_{i} = 134.14 + (0.096 \times advertising budget_{i})$$

```{r}
134.14 + (.096*666)
```

<br>

### 7.6 다중회귀 : 기초

$$Y_{i} = (b_{0} + b_{1}X_{1i} + b_{2}X_{2i} + ... + b_{n}X_{ni}) + \epsilon_{i}$$

<br>

#### 7.6.2 제곱합, $R$, $R^{2}$

- multiple $R^{2}$

<br>

#### 7.6.3 절약성에 따라 수정된 적합도

- $R^{2}$의 큰 문제점은 변수를 추가할 수록 점점 커진다는 것이다. 이를 극복하기 위한 수단으로 $R^{2}$을 조금 수정한 아카이케 정보기준(AIC)이 있다.

$$AIC = n\ln(\frac{SSE}{n}) + 2k$$

<br>

#### 7.6.4 여러 회귀 방법

- 예측변수들을 어떻게 추가하느냐는 중요한 문제이다.

<br>

##### 7.6.4.1 위계적 방법

- 알려진 변수들을 먼저 도입하고, 그 변수 중에서는 결과 예측의 중요도가 높은 것을 낮은 것보다 먼저 도입한다는 것이다. 

<br>

##### 7.6.4.2 강제 도입법

- 모든 예측변수를 모형에 동시에 도입하는 것이다. 

<br>

##### 7.6.4.3 단계별 방법

- stepwise regression

- 단계적 회귀에서는 모형에 예측변수들을 도입하는 순서를 순수한 수학적 기준에 기초해서 결정한다. 

- 단순상관이 가장 높은 예측변수를 선택한다. 두 번째 예측변수를 선택할 때에는 결과의 준편상관이 가장 큰 것을 고른다. 첫 예측변수가 결과변수의 변동의 40%를 설명한다고 상상해 보자. 그러면 변동의 60%는 여전히 설명되지 않은 상태이다. 컴퓨터는 준편상관을 이용해서, 변동의 나머지 60%를 최대한 많이 설명하는 변수를 찾는다. 

- 멈출 시점을 판단할 때는 AIC를 사용한다. R은 변수를 추가할 때마다 이 값을 갱신해서, 만일 이 값이 이전보가 작아지게 하는 변수가 더 이상 없으면 변수 추가를 중단한다.

<br>

##### 7.6.4.4 전부분집합 방법

- 변수들의 모든 조합을 시도해서 최량적합을 찾는다.

<br>

##### 7.6.4.5 방법의 선택

- 일반적인 법칙은 예측변수가 적을수록 좋다는 것, 그리고 견고한 이론적 근거가 있는 예측변수들만 포함시켜야 한다는 것이다. 예측변수는 최대한 깐깐하게 골라야 한다.

<br>

### 7.7 회귀모형의 정확도 평가

- 일반화(generalization)

<br>

#### 7.7.1 회귀모형의 평가 1 : 진단

- 아주 영향력이 큰 사례라도 그 잔차는 작을 수 있다.

<br>

##### 7.7.1.1 이상치와 잔차

- 잔차가 특히나 큰 사례는 이상치일 가능성이 있다.

- 이상치를 검출하려면 `특히나 큰` 잔차를 찾아야 하는데, 비표준화 잔차에서는 특히나 크다는 것이 어느 정도인지에 대한 보편적인 기준이 없다. 이 문제를 극복하기 위해 표준화잔차라는 것을 사용한다.

- 표준화 잔차는 보통의 잔차들을 해당 표준편차 추정값으로 나눈 것이다. 푠준화잔차는 잔차를 z 점수로 변환한 것이다.

- z 점수 중 95%가 -1.96과 +1.96 사이이고, 99%가 -2.58과 +2.58 사이, 그리고 99.9%가(즉, 거의 전부가) -3.29과 +3.29 사이임을 배웠다.

- 첫째로, 크기(절대값)가 3.29보다 큰 표준화잔차는 문제가 될 수 있다.
- 둘째로, 표준화잔차의 크기(절대값)가 2.58보다 큰 표본 사례들이 전체 표본 사례의 1% 이상이라는 것은 모형의 오차 수준이 받아들일 수 없는 정도라는 증거이다.
- 셋째로, 표준화잔차의 크기가 1.96보다 큰 표본 사례가 전체의 5% 이상이라는 것은 모형이 실제 자료를 그리 잘 대표하지 않는다는 증거이다.

<br>

##### 7.7.1.2 영향력이 큰 사례들

- 수정 예측값(adjusted predicted value): 해당 사례를 제외한 자료로 만든 모형이 예측한 값

- 수정 예측값과 원래의 예측값의 차이를 DFFit으로 표기한다. 

- 수정 예측값에 기초한 잔차, 즉 수정 예측값과 원래의 관측값의 차이를 살펴볼 수 있다. 그러한 잔차를 제외 잔차(deleted residual)라고 부르고, 그것을 표준오차로 나누어서 표준화한 값을 스튜던트와 잔차라고 부른다. 스튜던트와 잔차는 스튜던트의 t 분포를 따른다.



- 스튜던트화 잔차는 하나의 사례가 그 사례에 대한 모형의 예측 능력에 미치는 영향을 평가하는데 아주 유용하다. 그러나 스튜던트와 잔차는 한 사례가 모형 전체에 미치는 영향(즉, 모든 사례에 대한 모형의 예측 능력에 미치는 영향)에 관해서는 그 어떤 정보도 재공하지 않는다. 

- 한 사례가 모형 전체에 미치는 영향을 보여주는 통계량은 쿡의 거리이다. 이 거리가 1보다 크면 문제가 될 수 있다.

- 영향력의 또 다른 측도는 지렛대(leverage) 값이라고도 부르는 모자 값(hat value)이다. 이것은 결과변수의 실제 측정값이 예측값에 미치는 영향을 측정한 것이다. 평균 지렛대값은 $(k+1)/n$으로 정의되는데, 여기서 k는 모형의 예측변수 개수이고 n은 참가자의 수이다. 

- 모든 사례를 포함해서 추정한 매개변수와 특정 사례를 제외해서 추정한 매개변수의 차이를 흔히 DFBeta로 표기한다.

<br>

##### 7.7.1.3 진단 통계량애 대한 마지막 한 마디

- 만일 어떤 점이 Y축에서 유의한 이상치로 판명되었지만 그 점의 쿡의 거리가 $<1$이면, 그 점은 회귀분석에 큰 영향을 미치지 않으므로 굳이 삭제할 필요가 없다. 그러나 모형이 그런 점에 적합되지 않은 이류를 이해하기 위해 그런 점을 좀 더 연구할 필요는 있다.


<br>

#### 7.7.2 회귀모형의 평가: 일반화

- 회귀모형을 일반화하려면 먼저 그에 깔린 바탕 가정들이 성립하는지 확인해야 한다. 그리고 교차 타당성 검증을 통해서 모형이 실제로 일반화되는지 검사해야 한다.

<br>

##### 7.7.2.1 가정검점

 - 변수의 종류: 연속이자 양적 변수이어야 한다.
 
 - 0이 아닌 분산
 
 - 완전 다중공선성의 부재
 
 - 외부 변수와는 무관한 예측변수: 결과를 모형만큼이나 잘 예측할 수 있는 다른 변수들이 존재하는 것이므로
 
 - 등분산성: 예측변수들의 각 수준에서 잔차 항들의 분산이 일정해야 한다.
 
 - 오차의 독립성: 임의의 두 관측값의 잔차들이 무관해야 한다. 자기상관이 없어야 한다. 오차의 독립성 가정은 오차들의 이연상관을 검사하는 더빈-왓슨 검정으로 확인한다. 2보다 작은 값은 양의 상관이고 2보다 큰 값은 음의 상관이다. 더빈-왓슨 검정은 자료의 순서에 의존한다.
 
- 오차의 정규분포: 

- 예측변수는 정규분포일 필요가 없다.

- 독립성: 결과변수의 모든 값이 독립적이어야 한다.

- 선형성: 예측변수의 값이 증가함에 따라 결과변수의 평균값들이 하나의 직선을 형성해 나가야 한다. 모형화하고자 하는 관계가 선형이어야 한다.

- 회귀의 가정들이 만족되면, 한 표본에서 얻은 모형을 해당 모집단에도 정확하게 적용할 가능성이 생긴다.

- 가정들이 모두 성립하는 표본으로부처 얻은 회귀 방정식의 계수들과 매개변수들을 가르켜 편향되지 않았다고 한다.

- 비편향 모형이 말하는 것은 표본에서 얻은 회귀모형이 평균적으로 모집단의 모형과 같다는 것이다. 

<br>

##### 7.7.2.2 모형의 타당성 검증

- 여러 표본에 대해 모형이 얼마나 정확한지 평가하는 것을 교차 타당성 검증이라고 한다. 

- 수정 $R^{2}$ 스타인의 공식

$$Adjusted R^{2} = 1 - \left[ \left( \frac{n-1}{n-k-1} \right)  \left(  \frac{n-2}{n-k-2}\right) \left( \frac{n+1}{n} \right)\right] \left( 1-R^{2} \right)$$

- 자료분할: 자료 집합을 무작위 두 부분으로 나누고, 각 절반으로 회귀모형을 구해서 두 모형을 비교한다. 80/20

<br>

##### 7.7.2.3 회귀에서 표본 크기의 중요성

- 무작위 자료로부터 얻은 R의 기대값은 $k/(N-1)$이므로, 표본이 작으면 무작위 자료에 강한 효과가 존재한다.

- 우리가 기대하는 R의 기대값은 0이다. 표본이 크면 R은 0에 수렴한다. 

- 모형의 전반적인 적합도를 검사할 때, 그린은 최소 표본 크기를 $50 + 8k$로 하라고 권한다. 여기서 $k$는 예측변수이다. 

- 개별 예측변수를 검사할 때 권장 최소 크기는 $104 + k$이다.


<br>

##### 7.7.2.4 공선성

- 예측변수들 사이에 완전공선성이 존재하면, 관련 방정식을 만족하는 계수들의 조합이 무한히 많아지기 때문에 회귀계수들을 고유하게 추정할 수 없게 된다. 간단히 말하면, 두 변수가 완전 상관이면 각 변수의 $b$값들을 서로 맞바꾸어 사용할 수 있다.

- **$b$들을 믿을 수 없게 된다.**: 공선성이 높아지면 $b$ 계수들의 표준오차도 커진다. 

- **R의 크기가 제한된다.**: 첫 예측변수가 설명하는 변동 부분을 제거하면, 남은 변동 중 둘째 변수가 설명하는 부분은 거의 없게 된다. (즉, 둘째 변수가 설명하는 고유 변동이 아주 작다.) 따라서, 결과의 전체 변동 중 두 예측변수가 설명하는 부분은 변수 하나만 사용했을 때보다 그리 크지 않다.

- **예측변수들의 중요도 평가가 어렵다.**

- 분산팽창인자(VIF: variance inflation factor, VIF): 10이상이면 걱정할 필요가 있다. VIF의 역수가 공차(tolerance)이다.

<br>

### 7.8 R을 활용한 다중상관분석

- R이 상당히 복잡한 몇몇 계산을 단 몇 초 안에 끝내는 것이 사실이긴 하지만, 항상 고품질의 회귀모형을 만들어 주는 것은 아니다. 그런 모형을 만들려면 사람의 두뇌가 필요하다. 

<br>

##### 7.8.2.2 R을 이용한 다중회귀: 기본모형

```{r}
album2 <- read.delim('Album Sales 2.dat', header = T)

album2 %>% head
```


- 첫 모형은 $adverts$ 하나만 예측변수로 사용하고 둘째 모형은 $adverts$와 $airplay$, $attract$를 예측변수로 사용한다.

```{r}
album_sales_2 <- lm(sales ~ adverts, data = album2)
```

```{r}
album_sales_3 <- lm(sales ~ adverts + airplay + attract, data = album2)
```

<br>

#### 7.8.3 기본 다중회귀의 해석

<br>

##### 7.8.3.1 모형 요약

```{r}
album_sales_2 %>% summary()
```



```{r}
album_sales_3 %>% summary()
```


- $Adjusted R-squared$와 $R-squared$ 값의 차이는 .5%이다. 따라서 이 모형은 교차 타당성이 아주 좋다고 할 수 있다.

<br>

##### 7.8.3.2 모형 매개변수

$$판매량_{i} = b_{0} + b_{1} 광고비_{i} + b_{2} 방송횟수_{i} + b_{3} 매력_{i}$$

$$판매량_{i} = -26.61 + .08\ 광고비_{i} + 3.27 \ 방송횟수_{i} + 11.09 \  매력_{i}$$

- 출력에는 각 $b$ 값에 연관된 표준오차($Std.Error$)도 나와 있다. 표준오차는 서로 다른 표본들에 대해 $b$갑이 얼마나 달라지는지를 나타낸다. 이 표준오차는 $b$ 값이 0과 유의하게 다른지 판정하는데 쓰인다. $b$값이 0과 유의하게 다른지는 $t$ 통계량을 이용해서 검증할 수 있다.

- $b$값을 표준화한 버전이 더 쉽다. 이를 구하려면 `QuantPsyc::lm.beta()`함수를 이용한다. 

```{r}
library(QuantPsyc)
lm.beta(album_sales_3)
```

- 이들은 모형의 한 예측변수의 중요도를 잘 비교해서 나타낸다. 

```{r}
album2$sales %>% sd()
```

```{r}
album2$adverts %>% sd()
```

```{r}
album2$airplay %>% sd()
```

```{r}
album2$attract %>% sd()
```

 - 광고비($\beta = .511$): 광고비가 1 표준편차(485.655)만큼 증가하면 음반 판매량이 .511 표준편차만큼 증가함을 의미한다. 음반판매량의 표준편차는 80.699이므로, 증가량은  `r .511*80.699`이다. 즉, 광고비를 485.655 더 쓰면 음반이 41.240장 더 팔린다고 기대할 수 있다.

 - 방송 횟수($\beta = .512$): 라디오 방송 횟수가 1 표준편차 12.27회 만큼 증가하면 음반 판매량이 .512 표준편차만큼 증가함을 의미한다. `r .512*80.699` 만큼 증가한다.
따라서, 출시 전 한 주 동안 라디오 1이 음반의 노래를 12.27번 더 틀어줄 때마다 앨범이 41.318더 팔린다고 기대할 수 있다.

 - 밴드 매력($\beta = .192$): 밴드 매력 점수가 1 표준편차(1.40)만큼 증가하면 음반 판매량이 .192 표준편차만큼 증가함을 의미한다. `r .192*80.699` 만큼 증가한다. 따라서 매력이 1.40 높은 밴드의 음반이 15.49장 더 팔릴 것이라고 기대할 수 있다.
 
```{r}
confint(album_sales_3)
```
 

 - 표준화되지 않은 베타 값들의 95% 신뢰구간들은 그러한 표본들의 95%에서 $b$의 참 값이 해당 구간의 상, 하계 사이에 속하도록 만들어진 것이다. 다른 말로 하면, 100개의 표본에 대해 $b$의 신뢰구간들을 구했다면 그 중 95%의 신뢰구간에는 $b$의 참값이 포함된다.

 - 신뢰구간이 좁다는 것은 해당 표본의 $b$값이 모집단의 $b$의 참값에 가깝다는 것이다.

<br>

#### 7.8.4 모형의 비교

 - 위계적 회귀분석에서는 두 모형의 적합도를 비교해야 한다. 둘째 모형의 $R^{2}$이 첫 모형의  $R^{2}$보다 유의하게 큰 지 판단해야 한다.

$$F = \frac{(N-k-1)R^{2}}{k(1-R^{2})}$$

- 첫 모형의 $R^{2}$은 .335이다. 이를 위 공식에 대입하면 

$$F_{모형1} = 99.587$$

- $R^{2}$의 변화량과 새 모형(둘째 모형)의 $R^{2}$을 사용해야 하는데, 각각 $R^{2}_{변화}$와 $R^{2}_{2}$로 표기한다.

$$F_{변화} = \frac{( N - k_{2} - 1 )R^{2}_{변화}}{ k_{변화} (1 - R^{2}_{2}) }$$

- 변동의 양의 변화는 $F(2, 196) = 96.44, p < .001$로 유의하다. 이러한 변화 통계량들은 모형에 새 변수들을 추가해서 생긴 변화에 관한 정보를 제공한다.

<br>

##### R을 이용한 모형 비교

- anova(), 위계적 모형들만 비교할 수 있다.

```{r}
anova(album_sales_2, album_sales_3)
```

- $Pr(>F) = 2.2e-16$, $albumSales.2$에 비해 $albumSales.3$가 자료에 유의한 수준으로 더 적합하다.

<br>

### 7.9 회귀모형의 정확도 검정

<br>

#### 7.9.2 이상치와 영향이 큰 사례들

- casewise diagnostic(사례별 진단)

- 이상치 : 잔차는 `resid()` 함수로 구하고 표준화잔차는 `rstandard()` 함수로 구한다. 그리고 스튜던트화 잔차는 `rstudent()` 함수로 구한다.

- 영향이 큰 사례: 쿡의 거리는 `cook.distance()` 함수로 구한다. DFBeta는 dfbeta() 함수로, 
DFFit은 `diff()`로 구한다. 모자 값(지렛대)은 `hatvalues()` 함수로, 공분산비는 `covratio()` 함수로 구한다. 

```{r}
album2$residuals <- resid(album_sales_3)

album2$standized.residuals <- rstandard(album_sales_3)

album2$studentized.rediduals <- rstudent(album_sales_3)

album2$cooks.distance <- cooks.distance(album_sales_3)

# album2$dfbeta <- dfbeta(album_sales_3)

album2$dffit <- dffits(album_sales_3)

album2$leverage <- hatvalues(album_sales_3)

album2$covariance.ratios <- covratio(album_sales_3)
```

```{r}
album2 %>% round(3)
```

```{r}
album2 %>% round(3) %>% write_csv('Album Sales With Diagnosis.dat')
```
- (표준화잔차) 보통의 표본에서는 사례의 95%는 표준화잔차가 약 \pm2$이내라고 기대한다. 지금 사례가 200개이므로 그 중 10개(5%)는 표준화잔차가 그 범위 바깥일 것이다. 

```{r}
album2$standized.residuals > 2 | album2$standized.residuals < -2
```

```{r}
album2$large.residual <- album2$standized.residuals > 2 | album2$standized.residuals < -2
```

```{r}
album2$large.residual %>% sum()
```

- 잔차가 큰(2보다 크거나 -2보다 작은) 사례가 12개뿐임을 말해준다. 

```{r}
album2[album2$large.residual, c('sales', 'airplay', 'attract', 'adverts', 
                                'standized.residuals')]
```

- 사례들의 99%는 $\pm 2.5$이내이어야 한다. 따라서 사례들의 1%만 그 한계를 벗어나리라고 기대할 수 있다. 결과에 나온 사례 중 그 한계 바깥에 있는 사례는 두 개(1%)임이 확실하다(164번, 169번)

- 표준화잔차가 3을 넘는 169번 사레는 좀 더 조사해보아야 할 필요가 있다.

```{r}
album2 %>%
  rowid_to_column() %>%
  filter(large.residual == T) %>%
  dplyr::select(rowid, cooks.distance, leverage, covariance.ratios)
```

- (공분산비) 출력에는 공분산비(covariance ratio, CVR) 열이 있는데 상한과 하한을 비교해야 한다.

$$CVR_{i} > 1 + [3(k + 1)/n] = 1 + [3(3+1)/200] = 1.06$$

$$CVR_{i} > 1 - [3(k + 1)/n] = 1 - [3(3+1)/200] = .94$$

- 169번의 공분산비가 .85로 하한보다 현저하게 작다. 하지만 해당 쿡의 거리를 감안하면 이 사례가 크게 문제 되지 않는다.

<br>

#### 핵심정리(영향력이 큰 사례들)

회귀모형에 큰 영향을 미치는 사례들을 찾는 방법들은 다음과 같다.

- 표준화잔차의 절대값이 2보다 큰 사례들이 전체의 5%를 넘어서는 안 된다. 그리고 표준화잔차의 절대값이 2.5보다 큰 사례들이 전제의 약 1%를 넘어서는 안 된다. 3보다 큰 사례는 이상치일 수 있다.
'
- 쿡의 거리가 1보다 큰 사례는 모형에 영향을 미칠 가능성이 있다.

- 평균 모자 값(예측변수 개수 더하기 1을 표본 크기로 나눈 것)을 계산하고, 개별 모자 값이 평균값의 두 배 또는 세 배를 넘는 사례들을 찾아본다.

- 공분산비(CVR) 허용 범위의 상한과 하한을 계산한다. 상한은 1에 평균모자값의 세 배를 더한 것이고 하한은 1에서 평균 모자값의 세 배를 뺀 것이다. CVR이 그 범위를 벗어난 사례는 문제가 될 수 있다.

#### 7.9.3 독립성 가정의 평가

```{r}
durbinWatsonTest(album_sales_3)
```

```{r}
dwt(album_sales_3)
```

- 만일 검정통계량이 1보다 작거나 3보다 크면 주의할 필요가 있다. 2에 가까울 수록 좋다.

- p-value > .05 이므로 검정통계량이 유의하지 않다. 즉 독립성 가정이 성립한다.

<br>

#### 7.9.4 다중공선성 부재 가정의 평가

- 분산팽창인자(VIF)와 그 역수인 허용(tolerance) 통계량으로 평가한다.

```{r}
vif(album_sales_3)
```

```{r}
1/vif(album_sales_3)
```

```{r}
vif(album_sales_3) %>% mean()
```

- 만일 가장 큰 VIF가 10보다 크면 문제의 여지가 있는 것이다.
- 평균 VIF가 1보다 확연하게 크면 회귀모형이 편향되었을 수 있다.
- 허용통계량이 .2보다 작으면 모형에 뭔가 문제가 있을 가능성이 있다.
- 허용통계량이 .1보다 작으면 모형에 심각한 문제가 있는 것이다.

#### 7.9.5 잔차에 대한 여러 가정의 점검

- 잔차 그래프가 깔대기 형태이면 자료에 이분산성이 존재할 가능성이 있다.
- 잔차 그래프가 곡선 형태를 띤다면, 자료가 선형성 가정을 위반했을 가능성이 있다.
- 잔차가 정규분포로부터 벗어났는지 점검하는 또 다른 유용한 방법은 잔차(표준화잔차 또는 스튜던트화 잔차)들의 히스토그램을 살펴보는 것이다.

```{r}
album2$studentized.rediduals %>% hist()
```


#### 고품질 그래프

```{r}
album2$fitted <- album_sales_3$fitted.values
```

```{r}
album2 %>%
  ggplot(aes(studentized.rediduals)) + theme(legend.position = 'none') +
  geom_histogram(aes(y = ..density..), colour = 'black', fill = 'white') +
  labs(x = 'Studentized Residual', y = 'Density') -> histogram

histogram +
  stat_function(fun = dnorm, 
                args = list(mean = mean(album2$studentized.rediduals, na.rm = T), 
                            sd = sd(album2$studentized.rediduals, na.rm = T)), 
                            colour = 'red', size = 1) -> p1

p1
```

```{r}
qplot(sample = album2$studentized.rediduals) +
  stat_qq() +
  labs(x = 'Theoretical Values', 
       y = 'Observed Values') -> p2

p2
```

```{r}
album2 %>%
  ggplot(aes(fitted, studentized.rediduals)) +
  geom_point() +
  geom_smooth(method = 'lm', color = 'Blue') +
  labs(x = 'Fitted Values', 
       y = 'Studentized Residuals') -> p3

p3
```

```{r}
gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
```

#### 7.9.6 가정이 깨졌다면?

- 가정들이 깨졌다면 모형으로 발견한 것들을 표본 이상으로 일반화할 수 없다.
- 잔차들에서 이분산성이나 비정규성이 발견되었다면, 원본 자료를 변환해 볼 수 있다.
- 선형성 가정이 깨졌다면 선형회귀 대신 로지스틱 회귀를 적용해 볼 수있다.
- 마지막으로 강건한 회귀를 시도해 볼 수 있다.


### 7.10 강건한 회귀: 부트스트래핑

- boot 패키지 사용
- Bootstrap을 적용할 함수를 작성

```{r}
bootReg <- function(formula, data, indices) {
  d <- data[indices, ]
  fit <- lm(formula, data = d)
  return(coef(fit))
}
```

- 다음의 코드를 실행해서 부트스트랩 표본들을 얻는다.

```{r}
bootResults <- boot(statistic = bootReg, 
                    formula = sales ~ adverts + airplay + attract, 
                    data = album2, 
                    R = 2000)
```

- 신뢰구간을 확인한다.
- R은 bootResults에 담긴 통계량들의 이름을 알지 못하기 때문에, 이름 대신 bootResults 객체 안의 위치를 이용해서 각 통계량을 지정해야 한다. $index  = 1$을 지정하면 부트스트랩된 절편의 신뢰구간이 출력된다.

```{r}
boot.ci(bootResults, 
        type = 'bca',  # bias corrected accelerated(신뢰구간의 종류)
        index = 1)
```

```{r}
boot.ci(bootResults, type = 'bca', index = 2)
```

```{r}
boot.ci(bootResults, type = 'bca', index = 3)
```

```{r}
boot.ci(bootResults, type = 'bca', index = 4)
```


```{r}
confint(album_sales_3)
```

- 부트스트랩 신뢰구간들이 위계적 방식 신뢰구간들과 아주 비슷한 것을 알 수 있다.

### 7.11 다중회귀의 보고

```{r}
model <- album_sales_3
model.display <- epiDisplay::regress.display(model, crude = T, crude.p.value = T)
model.table <- model.display$table[rownames(model.display$table)!="", ]
kable(model.table, caption = model.display$first.line)
```


