ch07\_2
================
Daniel\_Kim
2020-03-31

  - [7.1. 이번 장에서 배우는 내용](#이번-장에서-배우는-내용)
  - [7.2 회귀의 소개](#회귀의-소개)
      - [7.2.1 직선에 관한 중요한 정보 몇 가지](#직선에-관한-중요한-정보-몇-가지)
      - [7.2.2. 최소제곱법](#최소제곱법)
      - [7.2.3. 적합도 평가: 제곱합, r, \(R^{2}\)](#적합도-평가-제곱합-r-r2)
      - [7.2.4. 개별 예측변수의 평가](#개별-예측변수의-평가)
      - [7.5.1 모형의 전반적인 적합도](#모형의-전반적인-적합도)
      - [7.5.2. 모형 매개변수들](#모형-매개변수들)
      - [7.5.3. 모형의 활용](#모형의-활용)
      - [핵심정리](#핵심정리)
  - [7.6 다중회귀 : 기초](#다중회귀-기초)
      - [7.6.2 제곱합, \(R\), \(R^{2}\)](#제곱합-r-r2)
      - [7.6.3 절약성에 따라 수정된 적합도](#절약성에-따라-수정된-적합도)
      - [7.6.4 여러 회귀 방법](#여러-회귀-방법)
          - [7.6.4.1 위계적 방법](#위계적-방법)
          - [7.6.4.2 강제 도입법](#강제-도입법)
          - [7.6.4.3 단계별 방법](#단계별-방법)
          - [7.6.4.4 전부분집합 방법](#전부분집합-방법)
          - [7.6.4.5 방법의 선택](#방법의-선택)
  - [7.7 회귀모형의 정확도 평가](#회귀모형의-정확도-평가)
      - [7.7.1 회귀모형의 평가 1 : 진단](#회귀모형의-평가-1-진단)
          - [7.7.1.1 이상치와 잔차](#이상치와-잔차)
          - [7.7.1.2 영향력이 큰 사례들](#영향력이-큰-사례들)
          - [7.7.1.3 진단 통계량애 대한 마지막 한 마디](#진단-통계량애-대한-마지막-한-마디)
      - [7.7.2 회귀모형의 평가: 일반화](#회귀모형의-평가-일반화)
          - [7.7.2.1 가정검점](#가정검점)
          - [7.7.2.2 모형의 타당성 검증](#모형의-타당성-검증)
          - [7.7.2.3 회귀에서 표본 크기의 중요성](#회귀에서-표본-크기의-중요성)

``` r
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
```

### 7.1. 이번 장에서 배우는 내용

<br>

### 7.2 회귀의 소개

  - 단순회귀, 다중회귀

  - 최소제곱법(method of least squares) 수학적 기법을 이용해 자료를 가장 잘 서술하는 직선을 선택

<br>

#### 7.2.1 직선에 관한 중요한 정보 몇 가지

  - 기울기 \(b_{1}\), 절편 \(b_{0}\)

  - \(b_{1}\), \(b_{0}\)들을 회귀계수라고 한다.

\[Y_{i} = (b_{0} + b_{1} X_{i}) + \epsilon_{i}\]

<br>

#### 7.2.2. 최소제곱법

  - line of best fit

<br>

#### 7.2.3. 적합도 평가: 제곱합, r, \(R^{2}\)

  - 평균 값과 관측값의 차이를 구하고, 그 차이 제곱들의 합을 총제곱합(total sum of squares)라고 한다.
    총제곱합을 \(SS_{T}\)로 표기한다. \(SS_{T}\)는 관측자료와 Y의 평균값의 차이들로 계산한
    값이다.

  - \(\sum(O_{i} - M_{i})^{2}\) 을 제곱잔차합 또는 잔차제곱합이라고 하고 \(SS_{R}\)로 표기한다.
    \(SS_{R}\)은 관측자료와 회귀선의 차이들로 계산한 값이다.

  - \(SS_{T}\)와 \(SS_{R}\)의 차이는 평균 대신 회귀모형을 사용했을 때 예측이 얼마나 향상되었는지를 나타낸다.
    다른 말로 하면 그 차이는 회귀모형을 사용했을 때 부정확도가 얼마나 줄어들 것이지를 보여준다. 이러한 향상량을
    모형제곱합(model sum of squares)이라 부르고 \(SS_{M}\)으로 표기한다.
    \(SS_{M}\)은 Y의 평균값과 회귀선의 차이들로 이루어진다.

  - \(SS_{M}\)의 값이 크다느 것은 결과변수의 예측을 위해 평균을 사용하는 것과 회귀모형을 사용하는 것이 많이 다르다는
    뜻이다. 평균은 가장 기본적인 모형이므로, 이 값이 크다는 것은 회귀모형이 이전보다 결과변수를 훨씬 잘 예측함을 의미한다.

  - \(R^{2}\)은 가장 기본적인 모형이 설명하는 변동의 양(\(SS_{T}\))에 대한, 주어진 모형이 설명하는 변동의
    양(\(SS_{M}\))의 비를 나타낸다.

\[R^{2} = \frac{SS_{M}}{SS_{T}}\]

  - \(R^{2}\)의 제곱근은 곧 피어슨 상관계수이다. 그런 만큼, 단순회귀에서 상관계수 \(r\)은 회귀모형의 전반적인
    적합도를 잘 추정하는 값이며 \(R^{2}\)은 상관관계의 실질적인 크기를 잘 추정하는 값이다.

  - \(F\) 같은 검정통계량들은 체계적 변동의 양을 비체계적 변동의 양으로 나눈 것이다. 다른 말로 하면 모형과 모형의
    오차를 비교한 것이다. 회귀분석에서 \(F\)는 \(SS_{M}(모형에 의한 향상)\)과
    \(SS_{R}(모형과 관측값의 차이)\)의 비이다.

  - 그런데 제곱합은 합한 차이들의 수에 의존하므로, 실제로는 평균 제곱들의 합을 사용한다. 그러한 합을 평균제곱(mean
    squares, MS)라고 한다. 이것은 그냥 제곱합을 자유도로 나누면 된다.

  - \(SS_{M}\)의 자유도는 모형의 변수 개수이고 \(SS_{R}\)의 자유도는 회귀분석으로 추정하는 매개변수(모수)
    개수를 관측값 개수에서 뺀 것이다. (이는 곧 상수를 포함한 베타 계수들의 개수이다.) 이 자유도들로 해당 제곱합을
    나누면 모형의 평균제곱(\(MS_{M}\))과 잔차 평균제곱(\(MS_{R}\))이 나온다.

  - \(F\)비는 기본모형을 사용했을 때와 비교할 때 새 모형이 결과의 예측을 얼마나 향상시키는지를 나타낸다.

\[F =  \frac{MS_{M}}{MS_{R}}\]

<br>

#### 7.2.4. 개별 예측변수의 평가

  - 만일 어떤 변수가 결과를 유의하게 예측한다면, 해당 \(b\)값이 0과는 달라야 한다. 이 가설을 \(t\) 검증으로
    검사할 수 있다. t-검정량은 \(b\)의 값이 0이라는 귀무가설을 검증한다. 따라서, 만일 그 검사의 결과가
    유의하다면 해당 예측변수가 결과를 예측하는 능력에 유의하게 기여한다는 확신이 커진다.

  - 우리의 관심사는 \(b\)가 그 추정값의 오차보다 큰 가이다. t검정은 표본 b 값들의 변동을 기준으로 할 때 모형의 b
    값이 0과 조금만 달라도 의미 있는 차이로 해석할 수 있다.

  - 귀무가설이 \(b\)가 0이라는 것이므로, 결과적으로 t 통계량은 그냥 \(b\)의 관측값을 해당 표준오차로 나눈 것이다.

\[t = \frac{b_{관측} - b_{기대}}{SE_{b}}\]

\[t = \frac{b_{관측}}{SE_{b}}\]

  - R은 \(b\)가 실제로 0일때 그러한 t의 관측값(또는 그보다 더 큰 값)이 발생할 정확한 확률을 제공한다. 이
    유의확률이 .05보다 작으면 과학자들은 b가 0과 유의하게 다르다고 가정하는 것이다.

<!-- end list -->

``` r
album1 <- read.delim('Album Sales 1.dat', header = T)
```

``` r
albumSales.1 <- lm(sales ~ adverts, data =album1)
albumSales.1 %>% summary()
```

    ## 
    ## Call:
    ## lm(formula = sales ~ adverts, data = album1)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -152.949  -43.796   -0.393   37.040  211.866 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 1.341e+02  7.537e+00  17.799   <2e-16 ***
    ## adverts     9.612e-02  9.632e-03   9.979   <2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 65.99 on 198 degrees of freedom
    ## Multiple R-squared:  0.3346, Adjusted R-squared:  0.3313 
    ## F-statistic: 99.59 on 1 and 198 DF,  p-value: < 2.2e-16

<br>

#### 7.5.1 모형의 전반적인 적합도

  - Multiple R-squared: 0.3346, Adjusted R-squared: 0.3313

<!-- end list -->

``` r
sqrt(0.3346)
```

    ## [1] 0.5784462

  - 두 변수(sales, adverts)간의 상관계수는 .58이다.

  - \(R^{2}\)이 .335라는 것은 광고비가 판매량 변동의 33.5%를 설명한다는 의미이다.

  - F-statistic: 99.59 on 1 and 198 DF, p-value: \< 2.2e-16

  - \(F\)비와 \(p-value\)가 있는데, 이 결과는 \(p < .001\) 수준에서 유의하다. 즉, 이 회귀모형을
    이용해서 음반 판매량을 예측하는 것이 음반 판매량의 평균을 사용해서 판매량을 예측할 때보다 유의하게 더 낫다는
    결론을 내릴 수 있다.

<br>

#### 7.5.2. 모형 매개변수들

  - (Intercept) 1.341e+02 7.537e+00 17.799 \<2e-16 에서 t 값을 계산하면

<!-- end list -->

``` r
134.10 / 7.537
```

    ## [1] 17.79223

  - adverts 9.612e-02 9.632e-03 9.979 \<2e-16 에서 t 값을 계산하면

<!-- end list -->

``` r
0.096/0.0096
```

    ## [1] 10

<br>

#### 7.5.3. 모형의 활용

<br>

#### 핵심정리

  - \(R^{2}\)은 애초에 존재하는 변동 중 모형이 설명하는 변동이 얼마나 되는지를 말해준다. 이 값은 결과변수의 변동 중
    예측변수의 변동과 공유되는 부분의 비율이다.

  - \(F\)비는 모형으로 설명할 수 없는 변동에 대한 모형으로 설명할 수 있는 변동의 비이다. 이것은 모형이 얼마나 나쁜지를
    기준으로 모형이 얼마나 좋은지를 나타낸 것이다.

\[album sales_{i} = 134.14 + (0.096 \times advertising budget_{i})\]

``` r
134.14 + (.096*666)
```

    ## [1] 198.076

<br>

### 7.6 다중회귀 : 기초

\[Y_{i} = (b_{0} + b_{1}X_{1i} + b_{2}X_{2i} + ... + b_{n}X_{ni}) + \epsilon_{i}\]

<br>

#### 7.6.2 제곱합, \(R\), \(R^{2}\)

  - multiple \(R^{2}\)

<br>

#### 7.6.3 절약성에 따라 수정된 적합도

  - \(R^{2}\)의 큰 문제점은 변수를 추가할 수록 점점 커진다는 것이다. 이를 극복하기 위한 수단으로 \(R^{2}\)을
    조금 수정한 아카이케 정보기준(AIC)이 있다.

\[AIC = n\ln(\frac{SSE}{n}) + 2k\]

<br>

#### 7.6.4 여러 회귀 방법

  - 예측변수들을 어떻게 추가하느냐는 중요한 문제이다.

<br>

##### 7.6.4.1 위계적 방법

  - 알려진 변수들을 먼저 도입하고, 그 변수 중에서는 결과 예측의 중요도가 높은 것을 낮은 것보다 먼저 도입한다는 것이다.

<br>

##### 7.6.4.2 강제 도입법

  - 모든 예측변수를 모형에 동시에 도입하는 것이다.

<br>

##### 7.6.4.3 단계별 방법

  - stepwise regression

  - 단계적 회귀에서는 모형에 예측변수들을 도입하는 순서를 순수한 수학적 기준에 기초해서 결정한다.

  - 단순상관이 가장 높은 예측변수를 선택한다. 두 번째 예측변수를 선택할 때에는 결과의 준편상관이 가장 큰 것을 고른다. 첫
    예측변수가 결과변수의 변동의 40%를 설명한다고 상상해 보자. 그러면 변동의 60%는 여전히 설명되지 않은 상태이다.
    컴퓨터는 준편상관을 이용해서, 변동의 나머지 60%를 최대한 많이 설명하는 변수를 찾는다.

  - 멈출 시점을 판단할 때는 AIC를 사용한다. R은 변수를 추가할 때마다 이 값을 갱신해서, 만일 이 값이 이전보가 작아지게
    하는 변수가 더 이상 없으면 변수 추가를 중단한다.

<br>

##### 7.6.4.4 전부분집합 방법

  - 변수들의 모든 조합을 시도해서 최량적합을 찾는다.

<br>

##### 7.6.4.5 방법의 선택

  - 일반적인 법칙은 예측변수가 적을수록 좋다는 것, 그리고 견고한 이론적 근거가 있는 예측변수들만 포함시켜야 한다는 것이다.
    예측변수는 최대한 깐깐하게 골라야 한다.

<br>

### 7.7 회귀모형의 정확도 평가

  - 일반화(generalization)

<br>

#### 7.7.1 회귀모형의 평가 1 : 진단

  - 아주 영향력이 큰 사례라도 그 잔차는 작을 수 있다.

<br>

##### 7.7.1.1 이상치와 잔차

  - 잔차가 특히나 큰 사례는 이상치일 가능성이 있다.

  - 이상치를 검출하려면 `특히나 큰` 잔차를 찾아야 하는데, 비표준화 잔차에서는 특히나 크다는 것이 어느 정도인지에 대한
    보편적인 기준이 없다. 이 문제를 극복하기 위해 표준화잔차라는 것을 사용한다.

  - 표준화 잔차는 보통의 잔차들을 해당 표준편차 추정값으로 나눈 것이다. 푠준화잔차는 잔차를 z 점수로 변환한 것이다.

  - z 점수 중 95%가 -1.96과 +1.96 사이이고, 99%가 -2.58과 +2.58 사이, 그리고 99.9%가(즉,
    거의 전부가) -3.29과 +3.29 사이임을 배웠다.

  - 첫째로, 크기(절대값)가 3.29보다 큰 표준화잔차는 문제가 될 수 있다.

  - 둘째로, 표준화잔차의 크기(절대값)가 2.58보다 큰 표본 사례들이 전체 표본 사례의 1% 이상이라는 것은 모형의 오차
    수준이 받아들일 수 없는 정도라는 증거이다.

  - 셋째로, 표준화잔차의 크기가 1.96보다 큰 표본 사례가 전체의 5% 이상이라는 것은 모형이 실제 자료를 그리 잘 대표하지
    않는다는 증거이다.

<br>

##### 7.7.1.2 영향력이 큰 사례들

  - 수정 예측값(adjusted predicted value): 해당 사례를 제외한 자료로 만든 모형이 예측한 값

  - 수정 예측값과 원래의 예측값의 차이를 DFFit으로 표기한다.

  - 수정 예측값에 기초한 잔차, 즉 수정 예측값과 원래의 관측값의 차이를 살펴볼 수 있다. 그러한 잔차를 제외
    잔차(deleted residual)라고 부르고, 그것을 표준오차로 나누어서 표준화한 값을 스튜던트와 잔차라고
    부른다. 스튜던트와 잔차는 스튜던트의 t 분포를 따른다.

  - 스튜던트화 잔차는 하나의 사례가 그 사례에 대한 모형의 예측 능력에 미치는 영향을 평가하는데 아주 유용하다. 그러나
    스튜던트와 잔차는 한 사례가 모형 전체에 미치는 영향(즉, 모든 사례에 대한 모형의 예측 능력에 미치는
    영향)에 관해서는 그 어떤 정보도 재공하지 않는다.

  - 한 사례가 모형 전체에 미치는 영향을 보여주는 통계량은 쿡의 거리이다. 이 거리가 1보다 크면 문제가 될 수 있다.

  - 영향력의 또 다른 측도는 지렛대(leverage) 값이라고도 부르는 모자 값(hat value)이다. 이것은 결과변수의
    실제 측정값이 예측값에 미치는 영향을 측정한 것이다. 평균 지렛대값은 \((k+1)/n\)으로 정의되는데, 여기서
    k는 모형의 예측변수 개수이고 n은 참가자의 수이다.

  - 모든 사례를 포함해서 추정한 매개변수와 특정 사례를 제외해서 추정한 매개변수의 차이를 흔히 DFBeta로 표기한다.

<br>

##### 7.7.1.3 진단 통계량애 대한 마지막 한 마디

  - 만일 어떤 점이 Y축에서 유의한 이상치로 판명되었지만 그 점의 쿡의 거리가 \(<1\)이면, 그 점은 회귀분석에 큰 영향을
    미치지 않으므로 굳이 삭제할 필요가 없다. 그러나 모형이 그런 점에 적합되지 않은 이류를 이해하기 위해 그런 점을 좀 더
    연구할 필요는 있다.

<br>

#### 7.7.2 회귀모형의 평가: 일반화

  - 회귀모형을 일반화하려면 먼저 그에 깔린 바탕 가정들이 성립하는지 확인해야 한다. 그리고 교차 타당성 검증을 통해서 모형이
    실제로 일반화되는지 검사해야 한다.

<br>

##### 7.7.2.1 가정검점

  - 변수의 종류: 연속이자 양적 변수이어야 한다.

  - 0이 아닌 분산

  - 완전 다중공선성의 부재

  - 외부 변수와는 무관한 예측변수: 결과를 모형만큼이나 잘 예측할 수 있는 다른 변수들이 존재하는 것이므로

  - 등분산성: 예측변수들의 각 수준에서 잔차 항들의 분산이 일정해야 한다.

  - 오차의 독립성: 임의의 두 관측값의 잔차들이 무관해야 한다. 자기상관이 없어야 한다. 오차의 독립성 가정은 오차들의
    이연상관을 검사하는 더빈-왓슨 검정으로 확인한다. 2보다 작은 값은 양의 상관이고 2보다 큰 값은 음의
    상관이다. 더빈-왓슨 검정은 자료의 순서에 의존한다.

  - 오차의 정규분포:

  - 예측변수는 정규분포일 필요가 없다.

  - 독립성: 결과변수의 모든 값이 독립적이어야 한다.

  - 선형성: 예측변수의 값이 증가함에 따라 결과변수의 평균값들이 하나의 직선을 형성해 나가야 한다. 모형화하고자 하는 관계가
    선형이어야 한다.

  - 회귀의 가정들이 만족되면, 한 표본에서 얻은 모형을 해당 모집단에도 정확하게 적용할 가능성이 생긴다.

  - 가정들이 모두 성립하는 표본으로부처 얻은 회귀 방정식의 계수들과 매개변수들을 가르켜 편향되지 않았다고 한다.

  - 비편향 모형이 말하는 것은 표본에서 얻은 회귀모형이 평균적으로 모집단의 모형과 같다는 것이다.

##### 7.7.2.2 모형의 타당성 검증

  - 여러 표본에 대해 모형이 얼마나 정확한지 평가하는 것을 교차 타당성 검증이라고 한다.

  - 수정 \(R^{2}\) 스타인의 공식

\[Adjusted R^{2} = 1 - \left[ \left( \frac{n-1}{n-k-1} \right)  \left(  \frac{n-2}{n-k-2}\right) \left( \frac{n+1}{n} \right)\right] \left( 1-R^{2} \right)\]

  - 자료분할: 자료 집합을 무작위 두 부분으로 나누고, 각 절반으로 회귀모형을 구해서 두 모형을 비교한다. 80/20

##### 7.7.2.3 회귀에서 표본 크기의 중요성

  - 무작위 자료로부터 얻은 R의 기대값은 \(k/(N-1)\)이므로, 표본이 작으면 무작위 자료에 강한 효과가 존재한다.

  - 우리가 기대하는 R의 기대값은 0이다.
