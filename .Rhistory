system.time(dt1[dt2, ])
system.time(merge(df1, df2))
m <- matrix(1, nrow = 1000, ncol = 100)
m
df <- as.data.frame(m)
dt <- as.data.table(m)
dt
for (i in 1:1000) {
dt[i, V1 := i]
}
dt
dt
lapply(1:10000, function(x) {
data.frame(val = x,
val2 = 2 * x,
val3 = 2/x,
val4 = 4 * x,
val5 = 4/x)
})
x <- lapply(1:10000, function(x) {
data.frame(val = x,
val2 = 2 * x,
val3 = 2/x,
val4 = 4 * x,
val5 = 4/x)
})
system.time(y <- do.call(rbind, x))
y
system.time(y <- do.call(rbind, x))
system.time(rbindlist(x))
system.time(y<- rbindlist(x))
y
library(foreach)
return(i)
foreach(i = 1:5) %do% {
return(i)
}
return(i)
foreach(i=1:5, .combine = c) %do% {
return(i)
}
return(i)
foreaxh(i=1:5, .combine = rbind) %do% {
return(i)
}
foreach(i=1:5, .combine = rbind) %do% {
return(i)
}
foreach(i=1:5, .combine = rbind) %do% {
return(data.frame(i))
}
foreach(i=1:5, .combine = rbind) %do% {
return(data.frame(val = i))
}
foreach(i=1:5, .combine = cbind) %do% {
return(data.frame(val = i))
}
library(doParallel)
registerDoParallel(cores = 4)
library(plyr)
big_data <- data.frame(
value = runif(NROW(LETTERS)*2000000),
group = rep(LETTERS, 2000000)
)
dlply(big_data, .(group), function(x) [
mean(x$value), .parallel =T
])
dlply(big_data, .(group), function(x) {
mean(x$value), .parallel =T
})
dlply(big_data, .(group), function(x) {
mean(x$value), .parallel =T})
dlply(big_data, .(group), function(x) {
mean(x$value)}, .parallel =T)
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(tidyverse)
library(data.table)
library(purrr)
readDauDates <- function(date.from, date.to) {
base_path <- './data/sample-data/section8/daily/dau/game-01'
date.from <- date.from  %>% as.Date()
date.to <- date.to %>% as.Date()
dates <- seq.Date(date.from, date.to, by = 'day')
file_name <- 'data.tsv'
whole_path <- paste0(base_path, '/', dates, '/', file_name)
dau <- whole_path %>% map(~read_tsv(.x)) %>% rbindlist()
return(dau)
}
readDauDates('2013-05-01', '2013-05-10')
readTypeDates <- function(data_type, game_name, date.from, date.to) {
base_path <- './data/sample-data/section8/daily'
data_type <- data_type %>% as.character() # dau, dpu, action...
game_name <- game_name %>% as.character() # game-01...
date.from <- date.from  %>% as.Date()
date.to <- date.to %>% as.Date()
dates <- seq.Date(date.from, date.to, by = 'day')
file_name <- 'data.tsv' # always data.tsv...
whole_path <- paste0(base_path, '/', data_type, '/', game_name, '/', dates, '/', file_name)
data <- whole_path %>% map(~read_tsv(.x)) %>% rbindlist()
return(data)
}
load('dau.RData')
load('dpu.RData')
load('action.RData')
dau %>% head
dpu %>% head
action %>% head
dau %>%
left_join(
dpu %>%
select('log_date', 'user_id', 'payment'),
by = c('log_date', 'user_id')
) %>%
mutate(is.payment = ifelse(is.na(payment), 0, 1)) %>%
mutate(payment = ifelse(is.na(payment), 0, payment)) -> dau_1
dau_1 %>%
mutate(log_year = lubridate::year(log_date) %>% as.character(),
log_month = lubridate::month(log_date) %>% as.character(),
log_day = lubridate::day(log_date) %>% as.character()) %>%
mutate(log_month = paste(log_year, log_month, sep  = '-')) %>%
group_by(log_month, user_id) %>%
summarise(sum.payment = sum(payment),
access_days = n()) -> mau
mau
library(ykmeans)
library(scales)
action <- as.data.frame(action)
# A47 항목이 랭킹 포인트를 의미합니다.
# variable name도 A47, target name도 A47로 합니다...
user.action2 <- ykmeans(action, 'A47', 'A47', 3)
user.action2$cluster %>% table()
user.action2$cluster %>% table() %>%
enframe() %>%
mutate(total_n = sum(value)) %>%
mutate(pct.value = value / total_n * 100) %>%
ggplot(aes(name, pct.value)) + geom_bar(stat = 'identity') +
xlab('Cluster') +
ylab('Percent of counts')
user.action2 %>%
arrange(desc(A47)) %>%
ggplot(aes(1:length(user_id), y = A47)) +
geom_line() +
xlab('User') +
ylab('Ranking Point(A47)') +
scale_y_continuous(label = comma)
user.action2 %>%
ggplot(aes(A47)) + geom_histogram()
user.action2 %>%
filter(cluster %in% c(2, 3)) -> user.action.h
user.action.h %>% head()
library(caret)
# 유저 행위에 대한 데이터만 추출
user.action.f <- user.action.h %>% select(matches('[A-Z]+[0-9]'))
# 어느 유저의 데이터인지 추적하기 위해 user.id를 row.names()로 설정
row.names(user.action.f) <- user.action.h$user_id
# user.action.f
# 정보량이 0에 가까운 변수를 삭제
nzv <- nearZeroVar(user.action.f)
user.action.f.filtered <- user.action.f[ , -nzv]
# user.action.f.filtered
# 변수간에 상관관계가 높은 것을 삭제
user.action.cor <- cor(user.action.f.filtered)
highly.cor.f <- findCorrelation(user.action.cor, cutoff = .7)
user.action.f.filtered_1 <- user.action.f.filtered[, -highly.cor.f]
user.action.f.filtered_1 %>% head()
user.action.f %>% dim
user.action.f.filtered_1 %>% dim
# 추후 K-Means 알고리즘을 위해 데이터가 정규화 되어 있는 것이 좋습니다. 그래서 scale = T 옵션을 추가합니다.
user.action.pca.base <- prcomp(user.action.f.filtered_1, scale = T)
user.action.pca.base$rotation %>% head()
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(tidyverse)
library(data.table)
library(purrr)
library(caret)
library(ykmeans)
library(scales)
library(fmsb)
readInstall <- function(game_name, target_day) {
base_path <- './data/sample-data/section9/snapshot/install'
game_name <- game_name %>% as.character() # game-01...
target_day <- target_day %>% as.character()
file_name <- 'install.csv'
whole_path <- paste0(base_path, '/', game_name, '/', target_day, '/', file_name)
data <- whole_path %>% fread()
return(data)
}
readDauDates <- function(game_name, date.from, date.to) {
base_path <- './data/sample-data/section9/daily'
data_type <- 'dau'
game_name <- game_name %>% as.character() # game-01...
date.from <- date.from  %>% as.Date()
date.to <- date.to %>% as.Date()
dates <- seq.Date(date.from, date.to, by = 'day')
file_name <- 'dau.csv' # always dau.tsv...
whole_path <- paste0(base_path, '/', data_type, '/', game_name, '/', dates, '/', file_name)
data <- whole_path %>% map(~fread(.x)) %>% rbindlist()
return(data)
}
readActionDates <- function(game_name, action_name, date.from, date.to) {
base_path <- './data/sample-data/section9/daily/'
data_type <- 'action'
game_name <- game_name %>% as.character() # game-01...
action_name <- action_name %>% as.character()
date.from <- date.from  %>% as.Date()
date.to <- date.to %>% as.Date()
dates <- seq.Date(date.from, date.to, by = 'day')
file_name <- paste0(action_name, '.csv') # always dau.tsv...
whole_path <- paste0(base_path, '/', data_type, '/', game_name, '/',  action_name, '/', dates, '/', file_name)
data <- whole_path %>% map(~fread(.x)) %>% rbindlist()
return(data)
}
install <- readInstall('game-01', '2013-09-30')
head(install)
dau <- readDauDates('game-01', '2013-06-01', '2013-09-30')
head(dau)
battle <- readActionDates('game-01', 'battle', '2013-06-01', '2013-08-31')
battle %>% head()
message <- readActionDates('game-01', 'message', '2013-06-01', '2013-08-31')
message %>% head()
hlp <- readActionDates('game-01', 'help', '2013-06-01', '2013-08-31')
hlp %>% head()
dau %>%
inner_join(install, by = 'user_id', suffix = c("", ".inst")) -> dau.inst
dau.inst %>% head
dau.inst %>%
mutate(log_date = as.Date(log_date),
log_date.inst = as.Date(log_date.inst)) %>%
mutate(elapsed_days = as.numeric(log_date - log_date.inst)) %>%
filter(elapsed_days >= 7 & elapsed_days <= 13) -> dau.inst.7_13
dau.inst.7_13 %>% head
dau.inst.7_13 %>%
group_by(user_id) %>%
summarise(density = n()/7) -> dau.inst.7_13.login.ds
dau.inst.7_13.login.ds %>% head()
install %>%
filter(log_date >= '2013-06-01' & log_date <= '2013-08-23') -> target.install
target.install %>% head
target.install %>%
left_join(dau.inst.7_13.login.ds, by = 'user_id') %>%
mutate(density = ifelse(is.na(density), 0, density)) -> target.install.login.ds
target.install.login.ds %>% head()
target.install.login.ds %>% arrange(desc(density)) %>% head
battle %>%
inner_join(install, by = 'user_id', suffix = c("", ".inst")) -> battle.inst
battle.inst %>% head
battle.inst %>%
mutate(log_date = as.Date(log_date),
log_date.inst = as.Date(log_date.inst)) %>%
mutate(elapsed_days = as.numeric(log_date - log_date.inst)) -> battle.inst.1
battle.inst.1 %>% head
battle.inst.1 %>%
filter(elapsed_days >= 0 & elapsed_days <= 6) -> battle.inst.2
battle.inst.2 %>% head
battle.inst.2 %>%
mutate(elapsed_days = paste0('d', as.character(elapsed_days))) %>%
select(user_id, count, elapsed_days) %>%
group_by(user_id, elapsed_days) %>%
summarise(sum.count = sum(count)) %>%
ungroup() %>%
spread(elapsed_days, sum.count) %>%
replace(is.na(.), 0) -> battle.inst.2_1
battle.inst.2_1 %>% head()
battle.inst.2_1 %>%
select(user_id) -> df.user_id
battle.inst.2_1 %>%
select(-user_id) %>%
mutate(total = rowSums(.)) %>%
mutate_if(is.numeric, list(~  round(./total, 2))) -> battle.inst.prop
df.user_id %>%
bind_cols(battle.inst.prop) -> battle.inst.prop_1
battle.inst.prop_1
battle.inst.2_1 %>%
select(-user_id) %>%
prcomp(scale = T) -> pr_battle.inst
pr_battle.inst$x %>% as_tibble() -> pr_battle.inst_1
df.user_id %>%
bind_cols(pr_battle.inst_1) -> pr_battle.inst_2
pr_battle.inst_2
message %>%
inner_join(install, by = 'user_id', suffix = c('', '.inst')) -> msg.inst
# 메세지 행동일과 이용시작일의 차이 즉 경과일수를 구합니다.
msg.inst %>%
mutate(log_date = as.Date(log_date),
log_date.inst = as.Date(log_date.inst)) %>%
mutate(elapsed_days = as.numeric(log_date - log_date.inst)) -> msg.inst.1
# 경과일수가 1주 이내인 것만 추출합니다.
msg.inst.1 %>%
filter(elapsed_days >= 0 & elapsed_days <= 6) -> msg.inst.2
# 경과일수별 메세지 행동횟수가 열에 오도록 데이터를 배치합니다.
msg.inst.2 %>%
mutate(elapsed_days = paste0('d', as.character(elapsed_days))) %>%
select(user_id, count, elapsed_days) %>%
group_by(user_id, elapsed_days) %>%
summarise(sum.count = sum(count)) %>%
ungroup() %>%
spread(elapsed_days, sum.count) %>%
replace(is.na(.), 0) -> msg.inst.2_1
msg.inst.2_1 %>% head
# 비율 데이터를 작성합니다.
msg.inst.2_1 %>%
select(user_id) -> df.user_id
msg.inst.2_1 %>%
select(-user_id) %>%
mutate(total = rowSums(.)) %>%
mutate_if(is.numeric, list(~round(./total, 2))) -> msg.inst.prop
df.user_id %>%
bind_cols(msg.inst.prop) -> msg.inst.prop_1
msg.inst.prop_1 %>% head
msg.inst.2_1 %>%
select(-user_id) %>%
prcomp(scale = T) -> pr_msg.inst
pr_msg.inst$x %>% as_tibble() -> pr_msg.inst_1
df.user_id %>%
bind_cols(pr_msg.inst_1) -> pr_msg.inst_2
pr_msg.inst_2 %>% head
hlp %>%
inner_join(install, by = 'user_id', suffix = c('', '.inst')) -> hlp.inst
# 메세지 행동일과 이용시작일의 차이 즉 경과일수를 구합니다.
hlp.inst %>%
mutate(log_date = as.Date(log_date),
log_date.inst = as.Date(log_date.inst)) %>%
mutate(elapsed_days = as.numeric(log_date - log_date.inst)) -> hlp.inst.1
# 경과일수가 1주 이내인 것만 추출합니다.
hlp.inst.1 %>%
filter(elapsed_days >= 0 & elapsed_days <= 6) -> hlp.inst.2
# 경과일수별 메세지 행동횟수가 열에 오도록 데이터를 배치합니다.
hlp.inst.2 %>%
mutate(elapsed_days = paste0('d', as.character(elapsed_days))) %>%
select(user_id, count, elapsed_days) %>%
group_by(user_id, elapsed_days) %>%
summarise(sum.count = sum(count)) %>%
ungroup() %>%
spread(elapsed_days, sum.count) %>%
replace(is.na(.), 0) -> hlp.inst.2_1
hlp.inst.2_1 %>% head
# 비율 데이터를 작성합니다.
hlp.inst.2_1 %>%
select(user_id) -> df.user_id
hlp.inst.2_1 %>%
select(-user_id) %>%
mutate(total = rowSums(.)) %>%
mutate_if(is.numeric, list(~round(./total, 2))) -> hlp.inst.prop
df.user_id %>%
bind_cols(hlp.inst.prop) -> hlp.inst.prop_1
hlp.inst.prop_1 %>% head
hlp.inst.2_1 %>%
select(-user_id) %>%
prcomp(scale = T) -> pr_hlp.inst
pr_hlp.inst$x %>% as_tibble() -> pr_hlp.inst_1
df.user_id %>%
bind_cols(pr_hlp.inst_1) -> pr_hlp.inst_2
pr_hlp.inst_2 %>% head
library(foreach)
# 클러스터 데이터 작성 함수
createClusterData <- function(aname, x, x.prop, x.pca) {
set.seed(2019)
df <- ldply(foreach(i = 3:6, combine = rbind) %do% {
km <- kmeans(x[, -1], i)
km.prop <- kmeans(x.prop[, -1], i)
km.pca <- kmeans(x.pca[, -1], i)
data.frame(user_id = x$user_id,
cluster.type = sprintf('%s%02d', aname, i),
freq.cluster.id = km$cluster,
prop.cluster.id = km.prop$cluster,
pca.cluster.id = km.pca$cluster
)
})
cluster.melt <- melt(df, id.vars = c('user_id', 'cluster.type'))
dcast(cluster.melt, user_id ~ cluster.type + variable)
}
battle.cluster <- createClusterData('battle', battle.inst.2_1, battle.inst.prop_1, pr_battle.inst_2)
battle.cluster %>% head
msg.cluster <- createClusterData('msg', msg.inst.2_1, msg.inst.prop_1, pr_msg.inst_2)
msg.cluster %>% head
hlp.cluster <- createClusterData('hlp', hlp.inst.2_1, hlp.inst.prop_1, pr_hlp.inst_2)
hlp.cluster %>% head
target.install.login.ds %>%
left_join(battle.cluster, by = 'user_id') %>%
left_join(msg.cluster, by = 'user_id') %>%
left_join(hlp.cluster, by = 'user_id') %>%
replace(is.na(.), 0) -> cluster.data
cluster.data %>% head
cluster.data %>% head
cluster.data %>%
dplyr::select(-log_date, -install_time, -gender, -generation, -device_type) %>%
gather(variable, value, -user_id, -density) -> cluster.data.gathered
cluster.data.gathered %>% head
cluster.data.gathered %>%
group_by(variable, value) %>%
summarise(avg.density = mean(density)) -> cluster.data.avg
cluster.data.avg %>% head()
# 새로운 클러스터 번호  부여
cluster.data.avg %>%
arrange(variable, avg.density) %>%
group_by(variable) %>%
mutate(value2 = sort(value)) -> cluster.data.avg_1
cluster.data.avg_1 %>% head()
cluster.data.gathered %>%
inner_join(cluster.data.avg_1, by = c('variable', 'value')) -> cluster.data.gathered_1
cluster.data.gathered_1 %>%
select(user_id, density, variable, value2) %>%
spread(variable, value2) -> cluster.data_1
cluster.data_1 %>% head()
library(rpart)
fit <- rpart(density ~ ., cluster.data_1[, -1])
print(fit)
library(rpart.plot)
rpart.plot(fit)
cluster.data.gathered_1 %>%
filter(variable == 'hlp04_pca.cluster.id') %>%
select(user_id, avg.density, value2) %>%
rename(cluster = value2) -> cluster.data_2
cluster.data_2 %>% head
hlp.inst.prop_1 %>%
inner_join(cluster.data_2, by = 'user_id') %>%
count(cluster)
library(rpart)
fit <- rpart(density ~ ., cluster.data_1[, -1])
print(fit)
cluster.data %>%
dplyr::select(-log_date, -install_time, -gender, -generation, -device_type) %>%
gather(variable, value, -user_id, -density) -> cluster.data.gathered
cluster.data.gathered %>% head
setwd("~/rstat_andy_field")
album2 <- read.delim('Album Sales 2.dat', header = T)
album2 <- read.delim('Album Sales 2.dat', header = T)
album2 %>% head
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
album2 <- read.delim('Album Sales 2.dat', header = T)
album2 %>% head
album_sales_2 <- lm(sales ~ adverts, data = alubm2)
album_sales_2 <- lm(sales ~ adverts, data = album2)
album_sales_3 <- lm(sales ~ adverts + airplay + attract, data = album2)
album_sales_2 %>% summary()
album_sales_3 %>% summary()
library(QuantPsyc)
lm.beta(album_sales_3)
album2$adverts %>% sd()
album2$sales %>% sd()
album2$airplay %>% sd()
album2$attract %>% sd()
confint(album_sales_3)
confint(album_sales_3)
confint(album_sales_3)
confint(album_sales_3)
knitr::opts_chunk$set(echo = TRUE)
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
album2 <- read.delim('Album Sales 2.dat', header = T)
album2 %>% head
album_sales_2 <- lm(sales ~ adverts, data = album2)
album_sales_3 <- lm(sales ~ adverts + airplay + attract, data = album2)
album_sales_2 %>% summary()
album_sales_3 %>% summary()
library(QuantPsyc)
lm.beta(album_sales_3)
album2$sales %>% sd()
album2$adverts %>% sd()
album2$airplay %>% sd()
album2$attract %>% sd()
confint(album_sales_3)
